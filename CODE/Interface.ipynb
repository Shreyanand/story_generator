{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING AND LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.linalg import norm\n",
    "\n",
    "experiment = \"seperate_models\"\n",
    "\n",
    "train_vectors = np.load(\"data/\"+ experiment + \"/train_vectors.npy\")\n",
    "train_sentences = np.load(\"data/\"+ experiment + \"/train_sentences.npy\")\n",
    "train_vectors = train_vectors / norm(train_vectors)\n",
    "\n",
    "vec = train_vectors[::5], train_vectors[1::5], train_vectors[2::5], train_vectors[3::5], train_vectors[4::5]\n",
    "sen = train_sentences[::5], train_sentences[1::5], train_sentences[2::5], train_sentences[3::5], train_sentences[4::5]\n",
    "\n",
    "dataset1 = np.asarray(vec[0:2])\n",
    "dataset2 = np.asarray(vec[0:3])\n",
    "dataset3 = np.asarray(vec[0:4])\n",
    "dataset4 = np.asarray(vec[0:5])\n",
    "\n",
    "vec = None\n",
    "\n",
    "sentences1 = np.asarray(sen[0:2])\n",
    "sentences2 = np.asarray(sen[0:3])\n",
    "sentences3 = np.asarray(sen[0:4])\n",
    "sentences4 = np.asarray(sen[0:5])\n",
    "\n",
    "sen = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITON AND PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0, bidirectional=True)       \n",
    "        self.lin = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(input_seq, input_lengths, batch_first=True)\n",
    "\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs , batch_first=True)\n",
    "\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "\n",
    "        output = self.lin(outputs[:,-1,:].unsqueeze(1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryVectors(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, sentences):\n",
    "        self.dataset = dataset\n",
    "        self.type = self.dataset.shape[0]\n",
    "        self.sen = sentences\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      \n",
    "        if self.type == 2:\n",
    "            X = [self.dataset[0][idx]]\n",
    "            y = [self.dataset[1][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx]]\n",
    "          \n",
    "          \n",
    "        elif self.type == 3:\n",
    "            X = [self.dataset[0][idx], self.dataset[1][idx]]\n",
    "            y = [self.dataset[2][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx], self.sen[2][idx]]\n",
    "        \n",
    "        elif self.type == 4:\n",
    "            X = [self.dataset[0][idx], self.dataset[1][idx], self.dataset[2][idx]]\n",
    "            y = [self.dataset[3][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx], self.sen[2][idx], self.sen[3][idx]]\n",
    "        \n",
    "        elif self.type == 5:\n",
    "            X = [self.dataset[0][idx], self.dataset[1][idx], self.dataset[2][idx], self.dataset[3][idx]]\n",
    "            y = [self.dataset[4][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx], self.sen[2][idx], self.sen[3][idx], self.sen[4][idx]]\n",
    "        \n",
    "        \n",
    "        return [X, len(X), y, sentences]\n",
    "      \n",
    "def vocab_collate_func(batch):\n",
    "    X = []\n",
    "    y = []\n",
    "    lengths = []\n",
    "    sentences = []\n",
    "\n",
    "    for datum in batch:\n",
    "        X.append(datum[0])\n",
    "        lengths.append(datum[1])\n",
    "        y.append(datum[2])\n",
    "        sentences.append(datum[3])\n",
    "\n",
    "    return [torch.FloatTensor(X), torch.LongTensor(lengths), torch.FloatTensor(y), sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"model/model1.tar\", map_location={'cuda:0': 'cpu'})\n",
    "model2 = torch.load(\"model/model2.tar\", map_location={'cuda:0': 'cpu'})\n",
    "model3 = torch.load(\"model/model3.tar\", map_location={'cuda:0': 'cpu'})\n",
    "model4 = torch.load(\"model/model4.tar\", map_location={'cuda:0': 'cpu'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(qvec, vectors, array, k=5):\n",
    "    qvec = qvec / norm(qvec)\n",
    "    print(\"computing scores\")\n",
    "    scores = np.dot(qvec, vectors.T).flatten()\n",
    "    sorted_args = np.argsort(scores)[::-1]\n",
    "    sentences = [(array[a], scores[a]) for a in sorted_args[:k]]\n",
    "    for i, s in enumerate(sentences):\n",
    "        print (s, sorted_args[i])\n",
    "        \n",
    "def suggestions(vectors, sentences, dataset_vectors, dataset_sentences, k=5):\n",
    "    l, _ = vectors.shape\n",
    "    vectors = np.append(vectors, np.zeros((1,4800)), axis=0)\n",
    "    vectors = np.expand_dims(vectors, axis=1)\n",
    "    sentences = np.append(sentences, \"dummy sentence for label\")\n",
    "    sentences = np.expand_dims(sentences, axis=1)\n",
    "    test_dataset = StoryVectors(vectors, sentences)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               collate_fn=vocab_collate_func,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)\n",
    "    \n",
    "    if l == 1:\n",
    "        print(\"Calling model 1\")\n",
    "        model1.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model1(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k) \n",
    "        \n",
    "    elif l == 2:\n",
    "        print(\"Calling model 2\")\n",
    "        model2.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model2(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k)\n",
    "        \n",
    "    elif l == 3:\n",
    "        print(\"Calling model 3\")\n",
    "        model3.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model3(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k)\n",
    "        \n",
    "    elif l == 4:\n",
    "        print(\"Calling model 4\")\n",
    "        model4.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model4(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k)\n",
    "        \n",
    "    else: \n",
    "        print(\"Story too longgg.\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERFACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How it works? \n",
    "\n",
    "This is an interactive story generating system that uses human authoring along with the system's expertise to generate intriguing short stories. The system generates the first sentence, or the story, following which it makes suggestions for the next sentence. You can choose from the, suggestions you see in the list by typing the corresponding digit for your choosen next sentence,  or you can eneter a sentence which then becomes the part of the narration. This procedure continues till we have a short 5 sentence story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL SENTENCE \n",
      "\n",
      "Emily decided to invite Emily's boyfriend over .\n",
      "Emily was taking an English test .\n",
      "John was trying to reheat some pizza .\n",
      "John dreamed of one day owning a skateboard .\n",
      "John loved stories about time travel .\n"
     ]
    }
   ],
   "source": [
    "experiment = 'interface'\n",
    "story = []\n",
    "n = np.random.randint(0, len(sentences1[0]), 5)\n",
    "print(\"INITIAL SENTENCE \\n\")\n",
    "print('\\n'.join([sentences1[0][i].decode('UTF-8') for i in n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John hated airplanes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John hated airplanes.\n",
      "Converting to vectors... eta: 1 min\n",
      "Calling model 1\n",
      "predicting vectors\n",
      "computing scores\n",
      "(b\"John was sick of John's bandleader getting all the attention .\", 0.0021618346) 102201\n",
      "(b\"John was having trouble controlling John's Great Dane .\", 0.002161027) 96870\n",
      "(b\"John was worried sick about John's Dog .\", 0.0021608546) 62509\n",
      "(b\"John was nervous about John's driving test at the DMV .\", 0.0021597033) 108685\n",
      "(b\"John was driving John's humvee in the desert of Iraq .\", 0.0021568637) 61730\n",
      "(b\"John was very confident in John's team .\", 0.0021567023) 11296\n",
      "(b\"John was confident in John's ability .\", 0.0021548271) 104687\n",
      "(b\"John was furious at John for breaking John's TV .\", 0.0021542762) 11\n",
      "(b\"John was practicing John's equestrian ability .\", 0.0021527433) 47305\n",
      "(b\"John was trained to be a pilot and did it John's whole military career .\", 0.002152469) 103464\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors... eta: 1 min\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John took a train to Miami.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John hated airplanes. John took a train to Miami.\n",
      "Converting to vectors... eta: 1 min\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors... eta: 1 min\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John is on John's way to the mountains .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John is on a vacation with John's family . John is happy that John got to visit Cleveland . John is on John's way to the mountains .\n",
      "Converting to vectors... eta: 1 min\n",
      "Calling model 3\n",
      "predicting vectors\n",
      "computing scores\n",
      "(b'When John reaches the campground John sees a sign .', 0.002080483) 11887\n",
      "(b'Even though John is 50 John still screams when John sees one .', 0.0020136544) 64951\n",
      "(b\"Now John climbs onto John's rooftop to think quietly .\", 0.0020058143) 87624\n",
      "(b'John hits a hidden rock and ascends into the air .', 0.0019944683) 3138\n",
      "(b'John notices John has a cavity .', 0.00199311) 84143\n",
      "(b\"John gets over John's fear and rides the airplane to see them .\", 0.001988094) 83604\n",
      "(b\"John lowers John on one leg and twists John's body to enter the sedan .\", 0.0019829988) 115082\n",
      "(b'While walking John notices something on the side of the road .', 0.0019811895) 46421\n",
      "(b\"Suddenly John grabs John's chest .\", 0.0019796751) 16512\n",
      "(b'John decides John has to be one of the first to have it .', 0.0019788092) 58381\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors... eta: 1 min\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Suddenly John grabs John's chest .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John is on a vacation with John's family . John is happy that John got to visit Cleveland . John is on John's way to the mountains . Suddenly John grabs John's chest .\n",
      "Converting to vectors\n",
      "Calling model 4\n",
      "predicting vectors\n",
      "computing scores\n",
      "(b'John could feel John slipping .', 0.0018733903) 11233\n",
      "(b'John was forced to vacate immediately .', 0.0018732201) 23294\n",
      "(b'John kept having to turn John down .', 0.0018675218) 8853\n",
      "(b'John was barely able to stop John .', 0.001866482) 61799\n",
      "(b'John was glad John decided not to stop .', 0.0018607995) 109509\n",
      "(b'John continued to let John go .', 0.0018602792) 108914\n",
      "(b'John was able to quickly get to where John wanted .', 0.0018556078) 21123\n",
      "(b'John had to stop to ask for directions .', 0.0018469059) 71118\n",
      "(b'John was unable to stop in time .', 0.0018458194) 100638\n",
      "(b'John was nervous John was going to fail .', 0.0018428373) 51817\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL STORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John could feel John slipping .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL STORY: \n",
      "\n",
      "John is on a vacation with John's family .\n",
      "John is happy that John got to visit Cleveland .\n",
      "John is on John's way to the mountains .\n",
      "Suddenly John grabs John's chest .\n",
      "John could feel John slipping .\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"FINAL STORY: \\n\")\n",
    "print(\"\\n\".join(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John decided to just leave it alone .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL STORY: \n",
      "\n",
      "John was hanging out with friends .\n",
      "They decided to split a pizza .\n",
      "John ordered the pizza and waited for it to arrive .\n",
      "There was one slice of pizza left .\n",
      "John decided to just leave it alone .\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"FINAL STORY: \\n\")\n",
    "print(\"\\n\".join(story))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
