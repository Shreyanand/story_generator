{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STORY CLOZE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "n = 10\n",
    "csv_file = \"/Users/shrey/Text Generation/story_cloze/data/process_data.csv\"\n",
    "numpy_file = \"vectors_\"+ str(\"preprocessed\") + \".npy\"\n",
    "\n",
    "learning_rate = 3e-4\n",
    "num_epochs = 10 # number epoch to train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1, dropout=0.3):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        #self.embedding = embedding\n",
    "\n",
    "        # Initialize GRU; the input_size and hidden_size params are both set to 'hidden_size'\n",
    "        #   because our input size is a word embedding with number of features == hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers,\n",
    "                          dropout=(0 if n_layers == 1 else dropout), bidirectional=True)\n",
    "        \n",
    "        self.lin = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "#         # Convert word indexes to embeddings\n",
    "#         embedded = self.embedding(input_seq)\n",
    "#         # Pack padded batch of sequences for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(input_seq, input_lengths, batch_first=True)\n",
    "        # Forward pass through GRU\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        # Unpack padding\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs , batch_first=True)\n",
    "        #print(outputs.shape)\n",
    "        # Sum bidirectional GRU outputs\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "        \n",
    "        output = self.lin(outputs[:, -1, :])\n",
    "        #print(outputs.shape)\n",
    "        # Return output and final hidden state\n",
    "        #assert torch.equal(outputs[-1,:,:], hidden.squeeze(0))\n",
    "        #print(hidden.shape, outputs[:,-1,:].shape)\n",
    "        return output\n",
    "    \n",
    "model = BasicGRU(hidden_size = 4800)\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_0 = []\n",
    "story_1 = []\n",
    "class StoryVectors(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, numpy_file, csv_file):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        #\"/Users/shrey/Text Generation/story_cloze/data/stories.csv\"\n",
    "        # \"vectors_\"+ str(n) + \".npy\"\n",
    "        n = 10\n",
    "        self.sentences = pd.read_csv(csv_file).values[:n,1:].reshape(-1).tolist()\n",
    "        vecn = np.load(numpy_file)\n",
    "        vec = vecn.tolist()\n",
    "        \n",
    "        v1, v2, v3, v4, v5 = vec[::5], vec[1::5], vec[2::5], vec[3::5], vec[4::5]\n",
    "        story_0.append([v1[0], v2[0], v3[0], v4[0], v5[0]])\n",
    "        story_1.append([v1[1], v2[1], v3[1], v4[1], v5[1]])\n",
    "\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        m = len(v1)\n",
    "        for i in range(m):\n",
    "            self.X.append([v1[i], v2[i], v3[i], v4[i]])\n",
    "            self.y.append(v5[i])\n",
    "            #lengths.append(4)\n",
    "            self.X.append([v1[i], v2[i], v3[i]])\n",
    "            self.y.append(v4[i])\n",
    "            #lengths.append(3)\n",
    "            self.X.append([v1[i], v2[i]])\n",
    "            self.y.append(v3[i])\n",
    "            #lengths.append(2)\n",
    "            self.X.append([v1[i]])\n",
    "            self.y.append(v2[i])\n",
    "            #lengths.append(1)\n",
    "\n",
    "        assert (len(self.X) == len(self.y))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        return [self.X[idx], len(self.X[idx]), self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    lengths = []\n",
    "\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((4-datum[1], 0), (0,0)),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        X.append(padded_vec)\n",
    "        y.append(datum[2])\n",
    "        lengths.append(datum[1])\n",
    "        \n",
    "    ind_dec_order = np.argsort(lengths)[::-1]\n",
    "    X = np.array(X)[ind_dec_order]\n",
    "    lengths = np.array(lengths)[ind_dec_order]\n",
    "    y = np.array(y)[ind_dec_order]\n",
    "    return [torch.FloatTensor(X), \n",
    "            torch.LongTensor(lengths), torch.FloatTensor(y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = StoryVectors(numpy_file, csv_file)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_epochs):\n",
    "    # Train the model\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(num_epochs):\n",
    "        t0 = time.time()\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred, _ = model(data, lengths)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            #print(epoch, i,  loss.item())\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 1 == 0:\n",
    "                loss_data = loss.data[0]\n",
    "                #train_losses.append(loss_data)\n",
    "                print(\n",
    "                    'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.\n",
    "                    format(epoch, i * len(data), len(train_loader.dataset),\n",
    "                           100. * i / len(train_loader), loss_data))\n",
    "                \n",
    "        print('Time taken by the epoch: {} seconds'.format(time.time() - t0))\n",
    "\n",
    "            # validate every 100 iterations\n",
    "    #         if i > 0 and i % 100 == 0:\n",
    "    #             # validate\n",
    "    #             val_acc = test_model(val_loader, model)\n",
    "    #             print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format(\n",
    "    #                        epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "\n",
    "training(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicGRU(\n",
       "  (gru): GRU(4800, 4800, bidirectional=True)\n",
       "  (lin): Linear(in_features=4800, out_features=4800, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_file)\n",
    "model = torch.load(\"model/GRU_Ln_100.tar\", map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1995\n"
     ]
    }
   ],
   "source": [
    "array = df.values[:,3:].reshape(-1).tolist()\n",
    "vecn = np.load(\"vectors_\"+ str(\"preprocessed\") + \".npy\")\n",
    "vec = vecn.tolist()\n",
    "print(len(vec))\n",
    "\n",
    "def nn(qvec, vectors, array, k=5):\n",
    "    qvec /= np.linalg.norm(qvec)\n",
    "    vectors = np.asarray([ i / np.linalg.norm(i) for i in vectors.tolist()])\n",
    "    scores = np.dot(qvec, vectors.T).flatten()\n",
    "    #distr(scores)\n",
    "    #analyse(scores)\n",
    "    sorted_args = np.argsort(scores)[::-1]\n",
    "    sentences = [(array[a], scores[a]) for a in sorted_args[:k]]\n",
    "    for i, s in enumerate(sentences):\n",
    "        print (s, sorted_args[i])\n",
    "        \n",
    "#len(story_0[0][0])        \n",
    "# story_0s = [nn(i, vecn, array, k=1) for i in story_0[0]]\n",
    "# story_1s = [nn(i, vecn, array, k=1) for i in story_1[0]]\n",
    "# print(story_1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = StoryVectors(numpy_file, csv_file)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)\n",
    "\n",
    "d1, l1, la1 = iter(train_loader).next()\n",
    "\n",
    "d1[1,3,:].shape\n",
    "la1[1,:].shape\n",
    "\n",
    "p = 1\n",
    "q = 2\n",
    "pred = model(d1[p:q,:,:], torch.tensor([1]))\n",
    "pred = pred.squeeze().detach().numpy()\n",
    "\n",
    "# nn(vec[7], vecn, array)\n",
    "# array[7]\n",
    "\n",
    "# nn(vec[7], vecn, array)\n",
    "# array[7]\n",
    "print(\"Input Sentence\")\n",
    "nn(d1.numpy()[p:q,3,:].squeeze().tolist(), vecn, array, k=1)\n",
    "\n",
    "\n",
    "print(\"Actual Output\")\n",
    "nn(la1.numpy()[p:q,:].squeeze().tolist(), vecn, array, k=1)\n",
    "\n",
    "print(\"Predicted Output\")\n",
    "nn(pred.tolist(), vecn, array, k=20)\n",
    "\n",
    "act = la1.numpy()[p:q,:].squeeze().T\n",
    "analyse(pred, vecn, act)\n",
    "# norm_pred  = pred / np.linalg.norm(pred)\n",
    "\n",
    "# norm_act =  act / np.linalg.norm(act)\n",
    "# np.dot(pred, act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-285-d27673445b6c>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-285-d27673445b6c>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    for (l, r) in zip(lengths, ranks_batch):\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_dataset = StoryVectors(numpy_file, csv_file)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)\n",
    "\n",
    "def test_model(test_loader):\n",
    "    model.eval()\n",
    "    ranks1, ranks2, ranks3, ranks4 = [], [], [], []\n",
    "    for data, lengths, labels in train_loader:\n",
    "        pred = model(data, lengths)\n",
    "        #print(len(pred.tolist()), len(labels.tolist()))\n",
    "        ranks_batch = analyse(pred.tolist(), vecn, labels.tolist()\n",
    "        for (l, r) in zip(lengths, ranks_batch):\n",
    "            if l == 4:\n",
    "                ranks4.append(r)\n",
    "            elif l == 3:\n",
    "                ranks3.append(r)\n",
    "            elif l == 2:\n",
    "                ranks2.append(r)\n",
    "            elif l == 1:\n",
    "                ranks1.append(r)\n",
    "\n",
    "    return ranks1, ranks2, ranks3, ranks4\n",
    "\n",
    "ranks1, ranks2, ranks3, ranks4 = test_model(train_loader)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFCJJREFUeJzt3X+MZeV93/H3pyzGafwDMAPa7q6z2NmkIZWy0CmhoolcY5kfSb24DREoMiuXahMJV7actl5iqXGkItltbSqrLdG6UC+RY6D+IVY2bkwxrmWpQBa8YPCasGBi1rtlJwZjLDe04G//uM/U15M7M3d+3Jndp++XdHXPec5zzvnec+985sxz752TqkKS1K+/tt4FSJImy6CXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdW7DehcAcMYZZ9TWrVvXuwxJOqE88MADf1FVU4v1Oy6CfuvWrezfv3+9y5CkE0qSPx+nn0M3ktQ5g16SOmfQS1LnDHpJ6pxBL0mdGzvok5yU5GtJPtfmz05yX5LHk9yW5BWt/ZQ2f6gt3zqZ0iVJ41jKGf27gYND8x8CbqiqbcBzwDWt/Rrguar6WeCG1k+StE7GCvokm4FfA/5Tmw/wZuBTrcte4PI2vaPN05Zf1PpLktbBuGf0/w74F8CP2vzrgO9V1Utt/jCwqU1vAp4GaMufb/1/QpJdSfYn2T8zM7PM8iVJi1k06JP8OnCsqh4Ybh7RtcZY9uOGqj1VNV1V01NTi36Dd15bd39+2etK0v8PxvkXCBcCb0tyGfBK4DUMzvBPTbKhnbVvBo60/oeBLcDhJBuA1wLPrnrlkqSxLHpGX1XXVdXmqtoKXAl8qap+C7gH+I3WbSdwR5ve1+Zpy79UVX/ljF6StDZW8jn69wHvTXKIwRj8Ta39JuB1rf29wO6VlShJWokl/ffKqvoy8OU2/SRw/og+fwlcsQq1SZJWgd+MlaTOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1bpyLg78yyf1JHkryaJI/aO0fT/KtJAfabXtrT5KPJjmU5OEk5036QUiS5jfOFaZeBN5cVT9IcjLw1SRfaMv+eVV9ak7/S4Ft7fbLwI3tXpK0Dsa5OHhV1Q/a7MntttDFvncAt7T17gVOTbJx5aVKkpZjrDH6JCclOQAcA+6qqvvaouvb8MwNSU5pbZuAp4dWP9zaJEnrYKygr6qXq2o7sBk4P8nfAq4D/ibwd4DTgfe17hm1ibkNSXYl2Z9k/8zMzLKKlyQtbkmfuqmq7wFfBi6pqqNteOZF4D8D57duh4EtQ6ttBo6M2NaeqpququmpqallFS9JWtw4n7qZSnJqm/4p4C3AN2fH3ZMEuBx4pK2yD7i6ffrmAuD5qjo6keolSYsa51M3G4G9SU5i8Ivh9qr6XJIvJZliMFRzAPid1v9O4DLgEPBD4J2rX7YkaVyLBn1VPQycO6L9zfP0L+DalZcmSVoNfjNWkjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktQ5g16SOjfONWNfmeT+JA8leTTJH7T2s5Pcl+TxJLcleUVrP6XNH2rLt072IUiSFjLOGf2LwJur6peA7cAl7aLfHwJuqKptwHPANa3/NcBzVfWzwA2tnyRpnSwa9DXwgzZ7crsV8GbgU619L3B5m97R5mnLL0qSVatYkrQkY43RJzkpyQHgGHAX8ATwvap6qXU5DGxq05uApwHa8ueB161m0ZKk8Y0V9FX1clVtBzYD5wO/MKpbux919l5zG5LsSrI/yf6ZmZlx65UkLdGSPnVTVd8DvgxcAJyaZENbtBk40qYPA1sA2vLXAs+O2NaeqpququmpqanlVS9JWtQ4n7qZSnJqm/4p4C3AQeAe4Ddat53AHW16X5unLf9SVf2VM3pJ0trYsHgXNgJ7k5zE4BfD7VX1uSTfAG5N8q+ArwE3tf43AX+U5BCDM/krJ1C3JGlMiwZ9VT0MnDui/UkG4/Vz2/8SuGJVqpMkrZjfjJWkzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOjXPN2C1J7klyMMmjSd7d2j+Q5DtJDrTbZUPrXJfkUJLHklw8yQcgSVrYONeMfQn43ap6MMmrgQeS3NWW3VBV/3a4c5JzGFwn9heBvwH8tyQ/V1Uvr2bhkqTxLHpGX1VHq+rBNv0CcBDYtMAqO4Bbq+rFqvoWcIgR15aVJK2NJY3RJ9nK4ELh97WmdyV5OMnNSU5rbZuAp4dWO8zCvxgkSRM0dtAneRXwaeA9VfV94EbgjcB24Cjw4dmuI1avEdvblWR/kv0zMzNLLlySNJ6xgj7JyQxC/hNV9RmAqnqmql6uqh8BH+PHwzOHgS1Dq28GjszdZlXtqarpqpqemppayWOQJC1gnE/dBLgJOFhVHxlq3zjU7e3AI216H3BlklOSnA1sA+5fvZIlSUsxzqduLgTeAXw9yYHW9nvAVUm2MxiWeQr4bYCqejTJ7cA3GHxi51o/cSNJ62fRoK+qrzJ63P3OBda5Hrh+BXVJklaJ34yVpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzo1zzdgtSe5JcjDJo0ne3dpPT3JXksfb/WmtPUk+muRQkoeTnDfpByFJmt84Z/QvAb9bVb8AXABcm+QcYDdwd1VtA+5u8wCXMrgg+DZgF3DjqlctSRrbokFfVUer6sE2/QJwENgE7AD2tm57gcvb9A7glhq4Fzg1ycZVr1ySNJYljdEn2QqcC9wHnFVVR2HwywA4s3XbBDw9tNrh1iZJWgdjB32SVwGfBt5TVd9fqOuIthqxvV1J9ifZPzMzM24ZkqQlGivok5zMIOQ/UVWfac3PzA7JtPtjrf0wsGVo9c3AkbnbrKo9VTVdVdNTU1PLrV+StIhxPnUT4CbgYFV9ZGjRPmBnm94J3DHUfnX79M0FwPOzQzySpLW3YYw+FwLvAL6e5EBr+z3gg8DtSa4Bvg1c0ZbdCVwGHAJ+CLxzVSuWJC3JokFfVV9l9Lg7wEUj+hdw7QrrkiStEr8ZK0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0b55qxNyc5luSRobYPJPlOkgPtdtnQsuuSHEryWJKLJ1W4JGk845zRfxy4ZET7DVW1vd3uBEhyDnAl8Ittnf+Y5KTVKlaStHSLBn1VfQV4dszt7QBuraoXq+pbDC4Qfv4K6pMkrdBKxujfleThNrRzWmvbBDw91Odwa5MkrZPlBv2NwBuB7cBR4MOtPSP61qgNJNmVZH+S/TMzM8ssQ5K0mGUFfVU9U1UvV9WPgI/x4+GZw8CWoa6bgSPzbGNPVU1X1fTU1NRyypAkjWFZQZ9k49Ds24HZT+TsA65MckqSs4FtwP0rK1GStBIbFuuQ5JPAm4AzkhwGfh94U5LtDIZlngJ+G6CqHk1yO/AN4CXg2qp6eTKlS5LGsWjQV9VVI5pvWqD/9cD1KylKkrR6/GasJHXOoJekzhn0ktQ5g16SOmfQS1LnDHpJ6pxBL0mdM+glqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdW7RoE9yc5JjSR4Zajs9yV1JHm/3p7X2JPlokkNJHk5y3iSLlyQtbpwz+o8Dl8xp2w3cXVXbgLvbPMClDC4Ivg3YBdy4OmVKkpZr0aCvqq8Az85p3gHsbdN7gcuH2m+pgXuBU5NsXK1iJUlLt9wx+rOq6ihAuz+ztW8Cnh7qd7i1SZLWyWq/GZsRbTWyY7Iryf4k+2dmZla5DEnSrOUG/TOzQzLt/lhrPwxsGeq3GTgyagNVtaeqpqtqempqapllSJIWs9yg3wfsbNM7gTuG2q9un765AHh+dohHkrQ+NizWIckngTcBZyQ5DPw+8EHg9iTXAN8Grmjd7wQuAw4BPwTeOYGaJUlLsGjQV9VV8yy6aETfAq5daVGSpNXjN2MlqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpc4teYWohSZ4CXgBeBl6qqukkpwO3AVuBp4DfrKrnVlamJGm5VuOM/u9X1faqmm7zu4G7q2obcHeblyStk0kM3ewA9rbpvcDlE9iHJGlMKw36Ar6Y5IEku1rbWVV1FKDdn7nCfUiSVmBFY/TAhVV1JMmZwF1Jvjnuiu0Xwy6A17/+9SssQ5I0nxWd0VfVkXZ/DPgscD7wTJKNAO3+2Dzr7qmq6aqanpqaWkkZkqQFLDvok/x0klfPTgNvBR4B9gE7W7edwB0rLVKStHwrGbo5C/hsktnt/HFV/dckfwrcnuQa4NvAFSsvU5K0XMsO+qp6EvilEe3fBS5aSVGSpNXjN2MlqXMGvSR1zqCXpM4Z9JLUOYNekjpn0EtS5wx6SeqcQS9JnTPoJalzBr0kdc6gl6TOGfSS1DmDXpI6Z9BLUucMeknqnEEvSZ0z6CWpcxML+iSXJHksyaEkuye1H0nSwiYS9ElOAv4DcClwDnBVknMmsS9J0sImdUZ/PnCoqp6sqv8N3ArsmNC+JEkLWPbFwRexCXh6aP4w8MsT2hdbd38egKc++GuLzm/d/fl5+w23ze0/X9/hZcPrza1vodrm1jVqvVH7XKy++eocVfN8685X/9z15nuMCx3PhWoatb/5jv3cYzlfnfMZdYzn2+dCj31ULfM93nHrGrXeqJpGHcuFXrdz15m732FzX4ejntNxapiv/vme6/le/4sdn4W2sdBjH2efCz3upbxm5y6btFTV6m80uQK4uKr+SZt/B3B+Vf3ToT67gF1t9ueBx5a5uzOAv1hBuZN0vNZmXUtjXUtzvNYFx29ty63rZ6pqarFOkzqjPwxsGZrfDBwZ7lBVe4A9K91Rkv1VNb3S7UzC8VqbdS2NdS3N8VoXHL+1TbquSY3R/ymwLcnZSV4BXAnsm9C+JEkLmMgZfVW9lORdwJ8AJwE3V9Wjk9iXJGlhkxq6oaruBO6c1PaHrHj4Z4KO19qsa2msa2mO17rg+K1tonVN5M1YSdLxw3+BIEmdO6GDfj3/zUKSLUnuSXIwyaNJ3t3aP5DkO0kOtNtlQ+tc12p9LMnFE6ztqSRfb/vf39pOT3JXksfb/WmtPUk+2up6OMl5E6rp54eOyYEk30/ynvU6XkluTnIsySNDbUs+Rkl2tv6PJ9k5obr+TZJvtn1/NsmprX1rkv81dOz+cGidv91eA4da7ZlAXUt+7lb7Z3aeum4bqumpJAda+1oer/nyYX1eY1V1Qt4YvMn7BPAG4BXAQ8A5a7j/jcB5bfrVwJ8x+HcPHwD+2Yj+57QaTwHObrWfNKHangLOmNP2r4HdbXo38KE2fRnwBSDABcB9a/Tc/U/gZ9breAG/CpwHPLLcYwScDjzZ7k9r06dNoK63Ahva9IeG6to63G/Odu4H/m6r+QvApROoa0nP3SR+ZkfVNWf5h4F/uQ7Ha758WJfX2Il8Rr+u/2ahqo5W1YNt+gXgIINvBM9nB3BrVb1YVd8CDjF4DGtlB7C3Te8FLh9qv6UG7gVOTbJxwrVcBDxRVX++QJ+JHq+q+grw7Ih9LuUYXQzcVVXPVtVzwF3AJatdV1V9sapearP3Mvheyrxaba+pqv9Rg7S4ZeixrFpdC5jvuVv1n9mF6mpn5b8JfHKhbUzoeM2XD+vyGjuRg37Uv1lYKGgnJslW4Fzgvtb0rvbn182zf5qxtvUW8MUkD2TwDWSAs6rqKAxehMCZ61DXrCv5yR++9T5es5Z6jNajxn/M4Mxv1tlJvpbkvyf5lda2qdWyFnUt5blb6+P1K8AzVfX4UNuaH685+bAur7ETOehHjaGt+UeIkrwK+DTwnqr6PnAj8EZgO3CUwZ+OsLb1XlhV5zH476HXJvnVBfqu6XHM4At0bwP+S2s6Ho7XYuarZa2P3fuBl4BPtKajwOur6lzgvcAfJ3nNGta11OdurZ/Tq/jJE4o1P14j8mHervPUsCq1nchBv+i/WZi0JCczeBI/UVWfAaiqZ6rq5ar6EfAxfjzcsGb1VtWRdn8M+Gyr4ZnZIZl2f2yt62ouBR6sqmdajet+vIYs9RitWY3tTbhfB36rDS/Qhka+26YfYDD+/XOtruHhnYnUtYznbi2P1wbgHwK3DdW7psdrVD6wTq+xEzno1/XfLLTxv5uAg1X1kaH24fHttwOznwbYB1yZ5JQkZwPbGLwBtNp1/XSSV89OM3gj75G2/9l37HcCdwzVdXV71/8C4PnZPy0n5CfOstb7eM2x1GP0J8Bbk5zWhi3e2tpWVZJLgPcBb6uqHw61T2Vw7QeSvIHBMXqy1fZCkgva6/TqoceymnUt9blby5/ZtwDfrKr/NySzlsdrvnxgvV5jK3lneb1vDN6p/jMGv5nfv8b7/nsM/oR6GDjQbpcBfwR8vbXvAzYOrfP+VutjrPBd/QXqegODTzM8BDw6e1yA1wF3A4+3+9NbexhcJOaJVvf0BI/ZXwe+C7x2qG1djheDXzZHgf/D4KzpmuUcIwZj5ofa7Z0TqusQg3Ha2dfZH7a+/6g9xw8BDwL/YGg70wyC9wng39O+HLnKdS35uVvtn9lRdbX2jwO/M6fvWh6v+fJhXV5jfjNWkjp3Ig/dSJLGYNBLUucMeknqnEEvSZ0z6CWpcwa9JHXOoJekzhn0ktS5/wvbsVUkd0+XewAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "# from matplotlib import interactive\n",
    "# interactive(True)\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def distr(array):\n",
    "    plt.scatter([i for i in range(len(array))], sorted(array))\n",
    "    plt.savefig('1.pdf')\n",
    "    plt.show()\n",
    "    \n",
    "def freq(array):\n",
    "    plt.hist(array, bins=np.arange(min(array), max(array)+1))\n",
    "    plt.show()\n",
    "    \n",
    "def analyse(predicted, vectors, actual):\n",
    "    \n",
    "    assert len(predicted) == len(actual), \"Oh\"\n",
    "\n",
    "    vectors = np.asarray([ i / np.linalg.norm(i) for i in vectors.tolist()])\n",
    "    ranks = []\n",
    "    \n",
    "    for pred, act in zip(predicted, actual):  \n",
    "        pred /= np.linalg.norm(pred)\n",
    "        act /= np.linalg.norm(act)\n",
    "        scores = np.dot(pred, vectors.T).flatten()\n",
    "        score_actpred = np.dot(pred, act)\n",
    "        print(\"score of act and pred:\", score_actpred)\n",
    "        #distr(scores)\n",
    "        #analyse(scores)\n",
    "        rank = '-1'\n",
    "        sorted_scores = sorted(scores, reverse=True)\n",
    "        for index, score in enumerate(sorted_scores):\n",
    "            if np.isclose(score, score_actpred):\n",
    "                rank = index\n",
    "                break\n",
    "            \n",
    "        ranks.append(rank)\n",
    "        \n",
    "    return ranks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8380942"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = d1.numpy()[p:q,3,:].squeeze().tolist()\n",
    "np.linalg.norm(act-pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function exec in module builtins:\n",
      "\n",
      "exec(source, globals=None, locals=None, /)\n",
      "    Execute the given source in the context of globals and locals.\n",
      "    \n",
      "    The source may be a string representing one or more Python statements\n",
      "    or a code object as returned by compile().\n",
      "    The globals must be a dictionary and locals can be any mapping,\n",
      "    defaulting to the current globals and locals.\n",
      "    If only globals is given, locals defaults to it.\n",
      "\n"
     ]
    }
   ],
   "source": [
    " exec(open(\"filename.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello\\n'\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "# #subprocess.run([\"python\", \"import sys; print sys.version_info[0]\"], stdout=subprocess.PIPE)\n",
    "# subprocess.check_call([\"python\", \"\"])\n",
    "\n",
    "import subprocess\n",
    "\n",
    "#p = subprocess.check_output([\"python\", \"/Users/shrey/test.py\"])\n",
    "#p = subprocess.check_output([\"echo\" \"hi\"])\n",
    "#p = subprocess.run([\"echo $(python /Users/shrey/test.py)\"], shell=True, stdout=subprocess.PIPE)\n",
    "p1 = subprocess.run(['/usr/bin/python', '/Users/shrey/test.py'], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print (p1.stdout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Pack Padded and Pad packed #########################\n",
    "# Padd all your sequences with 0 so that they are the same length. \n",
    "# But, record the actual length (unpadded) of each sequence in lengths(int) vector\n",
    "# to the function pack_padded_sequence pass Batch_Size * Longest Sequence length * num_directions(other dimensions)\n",
    "# Also, int tensor length with len(length) = Batch_Size\n",
    "\n",
    "\n",
    "################ Rough Work #####################################\n",
    "\n",
    "# pack = torch.nn.utils.rnn.pack_padded_sequence(X_t, lengths , batch_first=True)\n",
    "# unpack, s = torch.nn.utils.rnn.pad_packed_sequence(pack, batch_first=True)\n",
    "\n",
    "# a = [torch.tensor([3,4,5,6]), torch.tensor([1,2,3]), torch.tensor([3,4])]\n",
    "# print(a)\n",
    "# b = torch.nn.utils.rnn.pad_sequence(a, batch_first=True)\n",
    "# print(b)\n",
    "# c = torch.nn.utils.rnn.pack_padded_sequence(b, batch_first=True, lengths=[4,3,2])\n",
    "# print(c)\n",
    "# d, _ = torch.nn.utils.rnn.pad_packed_sequence(c)\n",
    "# print(d)\n",
    "\n",
    "# batch_size = 3\n",
    "# max_length = 3\n",
    "# hidden_size = 2\n",
    "# n_layers =1\n",
    "\n",
    "# # container\n",
    "# batch_in = torch.zeros((batch_size, 1, max_length))\n",
    "\n",
    "# #data\n",
    "# vec_1 = torch.FloatTensor([[1, 2, 3]])\n",
    "# vec_2 = torch.FloatTensor([[1, 2, 0]])\n",
    "# vec_3 = torch.FloatTensor([[1, 0, 0]])\n",
    "\n",
    "# batch_in[0] = vec_1\n",
    "# batch_in[1] = vec_2\n",
    "# batch_in[2] = vec_3\n",
    "\n",
    "# batch_in = Variable(batch_in)\n",
    "\n",
    "# seq_lengths = [3,2,1] # list of integers holding information about the batch size at each sequence step\n",
    "\n",
    "# # pack it\n",
    "# # pack = torch.nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "# # unpack, _ = torch.nn.utils.rnn.pad_packed_sequence(pack)\n",
    "\n",
    "\n",
    "\n",
    "# steps = []\n",
    "# batch_sizes = []\n",
    "# X_t = X_t.transpose(0, 1)\n",
    "\n",
    "# # # lengths is a Tensor, so we must convert to [int] before reversed()\n",
    "# # lengths_iter = reversed(lengths.tolist())\n",
    "\n",
    "# # batch_size = X_t.size(1)\n",
    "\n",
    "# # if len(lengths) != batch_size:\n",
    "# #     raise ValueError(\"Expected `len(lengths)` to be equal to batch_size, but got \"\n",
    "# #                      \"{} (batch_size={}).\".format(len(lengths), batch_size))\n",
    "\n",
    "# # prev_l = 0\n",
    "# # for i, l in enumerate(lengths_iter):\n",
    "# #     if l > prev_l:\n",
    "# #         c_batch_size = batch_size - i\n",
    "# #         print(X_t[prev_l:l, :c_batch_size])\n",
    "# #         steps.append(X_t[prev_l:l, :c_batch_size].contiguous().view(-1, *X_t.size()[2:]))\n",
    "# #         batch_sizes.extend([c_batch_size] * (l - prev_l))\n",
    "# #         prev_l = l\n",
    "\n",
    "# #     elif prev_l > l:\n",
    "# #         raise ValueError(\"'lengths' array has to be sorted in decreasing order\")\n",
    "\n",
    "# padded_vec = np.pad(np.array([v1[0]]),\n",
    "#                                 pad_width=((3,0), (0,0)),\n",
    "#                                 mode=\"constant\", constant_values=0)\n",
    "# print(padded_vec[1,:])\n",
    "# len(v1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv(\"/Users/shrey/Text Generation/story_cloze/data/stories.csv\")\n",
    "\n",
    "# import numpy as np\n",
    "# n = 10 \n",
    "# array = df.values[:n,1:].reshape(-1).tolist()\n",
    "# vecn = np.load(\"vectors_\"+ str(n) + \".npy\")\n",
    "# vec = vecn.tolist()\n",
    "# len(vec)\n",
    "\n",
    "# def nn(qvec, vectors, array, k=5):\n",
    "#     #qvec /= norm(qvec)\n",
    "#     scores = np.dot(qvec, vectors.T).flatten()\n",
    "#     sorted_args = np.argsort(scores)[::-1]\n",
    "#     sentences = [array[a] for a in sorted_args[:k]]\n",
    "#     for i, s in enumerate(sentences):\n",
    "#         print (s, sorted_args[i])\n",
    "        \n",
    "# vt = vec[::6]\n",
    "# v1 = vec[1::6]\n",
    "# v2 = vec[2::6]\n",
    "# v3 = vec[3::6]\n",
    "# v4 = vec[4::6]\n",
    "# v5 = vec[5::6]\n",
    "\n",
    "# v0 = np.zeros(4800).tolist()\n",
    "# X = []\n",
    "# y = []\n",
    "# lengths = []\n",
    "# m = len(v1)\n",
    "# for i in range(m):\n",
    "#     X.append([v1[i], v2[i], v3[i], v4[i]])\n",
    "#     y.append(v5[i])\n",
    "#     lengths.append(4)\n",
    "#     X.append([v0, v1[i], v2[i], v3[i]])\n",
    "#     y.append(v4[i])\n",
    "#     lengths.append(3)\n",
    "#     X.append([v0, v0, v1[i], v2[i]])\n",
    "#     y.append(v3[i])\n",
    "#     lengths.append(2)\n",
    "#     X.append([v0 , v0 , v0 , v1[i]])\n",
    "#     y.append(v2[i])\n",
    "#     lengths.append(1)\n",
    "\n",
    "    \n",
    "# data = [ (k, m, l)  for k, m, l in sorted(zip(X,y,lengths), key=lambda pair: pair[2], reverse=True)]\n",
    "# X = list(zip(*data))[0]\n",
    "# y = list(zip(*data))[1]\n",
    "# lengths = list(zip(*data))[2]\n",
    "    \n",
    "# X = np.asarray(X) #.reshape(5, 8, 4, 4800) # X.shape is (samples, timesteps, features)\n",
    "# y = np.asarray(y) #.reshape(5, 8, 4800)\n",
    "# lengths = np.asarray(lengths) #.reshape(5, 8)\n",
    "\n",
    "# from torch.autograd import Variable\n",
    "# X_t =torch.FloatTensor(X)\n",
    "# y_t =torch.FloatTensor(y)\n",
    "# lengths = torch.IntTensor(lengths)\n",
    "# print(X_t.requires_grad)\n",
    "\n",
    "\n",
    "########################## Py torch Basics ###################\n",
    "# import torch\n",
    "# x = torch.ones(2, 2, requires_grad=True)\n",
    "# print(x)\n",
    "\n",
    "# y = x * 2\n",
    "# z = y + 5\n",
    "# out = z * z / 2\n",
    "# out = out.mean()\n",
    "\n",
    "# out.grad\n",
    "\n",
    "\n",
    "############ Laoding Validation ##############################\n",
    "\n",
    "# val_dataset = VocabDataset(val_data, char2id)\n",
    "# val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=vocab_collate_func,\n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_dataset = VocabDataset(test_data, char2id)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=vocab_collate_func,\n",
    "#                                            shuffle=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
