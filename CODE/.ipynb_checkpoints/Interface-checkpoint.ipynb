{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTING AND LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "experiment = \"seperate_models\"\n",
    "\n",
    "train_vectors = np.load(\"data/\"+ experiment + \"/train_vectors.npy\")[:2000]\n",
    "train_sentences = np.load(\"data/\"+ experiment + \"/train_sentences.npy\")[:2000]\n",
    "\n",
    "vec = train_vectors[::5], train_vectors[1::5], train_vectors[2::5], train_vectors[3::5], train_vectors[4::5]\n",
    "sen = train_sentences[::5], train_sentences[1::5], train_sentences[2::5], train_sentences[3::5], train_sentences[4::5]\n",
    "\n",
    "dataset1 = np.asarray(vec[0:2])\n",
    "dataset2 = np.asarray(vec[0:3])\n",
    "dataset3 = np.asarray(vec[0:4])\n",
    "dataset4 = np.asarray(vec[0:5])\n",
    "\n",
    "vec = None\n",
    "\n",
    "sentences1 = np.asarray(sen[0:2])\n",
    "sentences2 = np.asarray(sen[0:3])\n",
    "sentences3 = np.asarray(sen[0:4])\n",
    "sentences4 = np.asarray(sen[0:5])\n",
    "\n",
    "sen = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DEFINITON AND PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, hidden_size, n_layers=1):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=0, bidirectional=True)       \n",
    "        self.lin = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(input_seq, input_lengths, batch_first=True)\n",
    "\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        \n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs , batch_first=True)\n",
    "\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n",
    "\n",
    "        output = self.lin(outputs[:,-1,:].unsqueeze(1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryVectors(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, sentences):\n",
    "        self.dataset = dataset\n",
    "        self.type = self.dataset.shape[0]\n",
    "        self.sen = sentences\n",
    "\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      \n",
    "        if self.type == 2:\n",
    "            X = [self.dataset[0][idx]]\n",
    "            y = [self.dataset[1][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx]]\n",
    "          \n",
    "          \n",
    "        elif self.type == 3:\n",
    "            X = [self.dataset[0][idx], self.dataset[1][idx]]\n",
    "            y = [self.dataset[2][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx], self.sen[2][idx]]\n",
    "        \n",
    "        elif self.type == 4:\n",
    "            X = [self.dataset[0][idx], self.dataset[1][idx], self.dataset[2][idx]]\n",
    "            y = [self.dataset[3][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx], self.sen[2][idx], self.sen[3][idx]]\n",
    "        \n",
    "        elif self.type == 5:\n",
    "            X = [self.dataset[0][idx], self.dataset[1][idx], self.dataset[2][idx], self.dataset[3][idx]]\n",
    "            y = [self.dataset[4][idx]]\n",
    "            sentences = [self.sen[0][idx], self.sen[1][idx], self.sen[2][idx], self.sen[3][idx], self.sen[4][idx]]\n",
    "        \n",
    "        \n",
    "        return [X, len(X), y, sentences]\n",
    "      \n",
    "def vocab_collate_func(batch):\n",
    "    X = []\n",
    "    y = []\n",
    "    lengths = []\n",
    "    sentences = []\n",
    "\n",
    "    for datum in batch:\n",
    "        X.append(datum[0])\n",
    "        lengths.append(datum[1])\n",
    "        y.append(datum[2])\n",
    "        sentences.append(datum[3])\n",
    "\n",
    "    return [torch.FloatTensor(X), torch.LongTensor(lengths), torch.FloatTensor(y), sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = torch.load(\"model/model1_2000.tar\", map_location={'cuda:0': 'cpu'})\n",
    "model2 = torch.load(\"model/model2_2000.tar\", map_location={'cuda:0': 'cpu'})\n",
    "model3 = torch.load(\"model/model3_2000.tar\", map_location={'cuda:0': 'cpu'})\n",
    "model4 = torch.load(\"model/model4_2000.tar\", map_location={'cuda:0': 'cpu'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(qvec, vectors, array, k=5):\n",
    "    print(\"computing scores\")\n",
    "    scores = np.dot(qvec, vectors.T).flatten()\n",
    "    sorted_args = np.argsort(scores)[::-1]\n",
    "    sentences = [(array[a], scores[a]) for a in sorted_args[:k]]\n",
    "    for i, s in enumerate(sentences):\n",
    "        print (s, sorted_args[i])\n",
    "        \n",
    "def suggestions(vectors, sentences, dataset_vectors, dataset_sentences, k=5):\n",
    "    l, _ = vectors.shape\n",
    "    vectors = np.append(vectors, np.zeros((1,4800)), axis=0)\n",
    "    vectors = np.expand_dims(vectors, axis=1)\n",
    "    sentences = np.append(sentences, \"dummy sentence for label\")\n",
    "    sentences = np.expand_dims(sentences, axis=1)\n",
    "    test_dataset = StoryVectors(vectors, sentences)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                               batch_size=1,\n",
    "                                               collate_fn=vocab_collate_func,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)\n",
    "    \n",
    "    if l == 1:\n",
    "        print(\"Calling model 1\")\n",
    "        model1.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model1(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k) \n",
    "        \n",
    "    elif l == 2:\n",
    "        print(\"Calling model 2\")\n",
    "        model2.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model2(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k)\n",
    "        \n",
    "    elif l == 3:\n",
    "        print(\"Calling model 3\")\n",
    "        model3.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model3(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k)\n",
    "        \n",
    "    elif l == 4:\n",
    "        print(\"Calling model 4\")\n",
    "        model4.eval()\n",
    "        for data, lengths, labels, sentences in test_loader:\n",
    "                print(\"predicting vectors\")\n",
    "                pred = model4(data, lengths)\n",
    "        pred = pred.detach().numpy().squeeze()\n",
    "        nn(pred, dataset_vectors, dataset_sentences, k)\n",
    "        \n",
    "    else: \n",
    "        print(\"Story too longgg.\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTERFACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How it works? \n",
    "\n",
    "This is an interactive story generating system that uses human authoring along with the system's expertise to generate intriguing short stories. The system generates the first sentence, or the story, following which it makes suggestions for the next sentence. You can choose from the, suggestions you see in the list by typing the corresponding digit for your choosen next sentence,  or you can eneter a sentence which then becomes the part of the narration. This procedure continues till we have a short 5 sentence story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL SENTENCE \n",
      "\n",
      "Emily used to hate cleaning day , but that changed on Saturday .\n",
      "Emily spend all day baking a cake for Emily's daughter .\n",
      "One day Emily was on YouTube .\n",
      "John was visiting summer camp for the first time .\n",
      "John is camping .\n"
     ]
    }
   ],
   "source": [
    "experiment = 'interface'\n",
    "story = []\n",
    "n = np.random.randint(0, len(sentences1[0]), 5)\n",
    "print(\"INITIAL SENTENCE \\n\")\n",
    "print('\\n'.join([sentences1[0][i].decode('UTF-8') for i in n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-8515ce38f6db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Story so far: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'/Users/shrey/anaconda3/envs/py2/bin/python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text2vec.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors... eta: 1 min\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John did n't want to spend a lot of money .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John went to the market. John did n't want to spend a lot of money .\n",
      "Calling model 2\n",
      "predicting vectors\n",
      "computing scores\n",
      "(b'Peter went to the library to check out a book on basketball .', 1.0152367) 962\n",
      "(b'John found some leftovers from a restaurant .', 0.99243754) 372\n",
      "(b'John went to the store to buy the items needed for the repellant .', 0.9870586) 114\n",
      "(b\"John went to the bank to get a loan to start John's business .\", 0.9849243) 311\n",
      "(b'John asked for a refund for the pizza .', 0.98466194) 1189\n",
      "(b'John went to the bank and asked for a loan .', 0.9775698) 657\n",
      "(b'John went outside to retrieve the newspaper .', 0.9758084) 1826\n",
      "(b\"John left John's debit card at the bar .\", 0.9754853) 1745\n",
      "(b\"John stopped at a restaurant and left the unopened phone on John's seat .\", 0.97514606) 212\n",
      "(b\"John enjoyed John's sandwich and was glad John had n't spent extra money .\", 0.97461814) 1834\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " He bought cheap food.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John went to the market. John did n't want to spend a lot of money . He bought cheap food.\n",
      "Calling model 3\n",
      "predicting vectors\n",
      "computing scores\n",
      "(b\"It could barely keep up with John's workload .\", 0.86232746) 887\n",
      "(b'Unfortunately , John was grounded .', 0.8519374) 1666\n",
      "(b\"There were several sales on John's account .\", 0.85013354) 1747\n",
      "(b\"But when Emily saw mourners compliment Emily's work , Emily was happy .\", 0.84867895) 1988\n",
      "(b'It looked like John peed John .', 0.847754) 1383\n",
      "(b'It was all John could afford .', 0.8476577) 1196\n",
      "(b'The consensus was clean socks .', 0.844612) 203\n",
      "(b'It was full of vegetables and meat .', 0.8433764) 1317\n",
      "(b'And John felt regretful about all of the money John wasted .', 0.8391314) 1608\n",
      "(b'It was a pizzeria .', 0.83523697) 901\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " John was not happy with the quality of the food.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story so far: John went to the market. John did n't want to spend a lot of money . He bought cheap food. John was not happy with the quality of the food.\n",
      "Calling model 4\n",
      "predicting vectors\n",
      "computing scores\n",
      "(b'They decided John would cook every time they went camping .', 0.9054463) 1319\n",
      "(b\"John was a very clean person because of John's hygeine .\", 0.904766) 183\n",
      "(b\"John was nearly out of food in John's house .\", 0.9039933) 570\n",
      "(b'Peter was very sick and John had to take John to a doctor .', 0.9019178) 1074\n",
      "(b'When John went to India the first time , John was sick for a week .', 0.901726) 490\n",
      "(b\"John was pleased John had the family heirloom in John's home .\", 0.8996477) 1234\n",
      "(b\"But John's car got broken into while John was eating .\", 0.89806366) 213\n",
      "(b'As John was cooking , John could not find the ricotta cheese .', 0.89661825) 897\n",
      "(b'John fed John daily and had no idea that the dog was vicious .', 0.8965687) 231\n",
      "(b\"John was upset John could n't finish John's dinner .\", 0.89616954) 899\n"
     ]
    }
   ],
   "source": [
    "s = input()\n",
    "story.append(s)\n",
    "print(\"Story so far: \" + ' '.join(story))\n",
    "l = len(story)\n",
    "print(\"Converting to vectors\")\n",
    "p1 = subprocess.run(['/Users/shrey/anaconda3/envs/py2/bin/python', 'text2vec.py', ''.join(story)], stdin=None, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "vectors = np.load(\"data/\" + experiment + \"/\" + str(l) + \".npy\")\n",
    "suggestions(vectors, story, train_vectors, train_sentences, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL STORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL STORY: \n",
      "\n",
      "John went to the market.\n",
      "John did n't want to spend a lot of money .\n",
      "He bought cheap food.\n",
      "John was not happy with the quality of the food.\n",
      "John was upset John could n't finish John's dinner .\n"
     ]
    }
   ],
   "source": [
    "# s = input()\n",
    "# story.append(s)\n",
    "print(\"FINAL STORY: \\n\")\n",
    "print(\"\\n\".join(story))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
